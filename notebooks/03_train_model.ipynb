{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56b6442d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        review     label\n",
      "0    i loved this product, it works perfectly.  positive\n",
      "1           this exceeded all my expectations!  positive\n",
      "2    amazing quality, totally worth the price.  positive\n",
      "3  i'm extremely satisfied with this purchase.  positive\n",
      "4         great experience, i would buy again.  positive\n",
      "['positive' 'negative' 'neutral']\n",
      "Empty DataFrame\n",
      "Columns: [review, label]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../data/processed/clean_reviews_v2.csv\")\n",
    "print(df.head())\n",
    "print(df[\"label\"].unique())\n",
    "print(df[df[\"label\"].isna()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b938b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Documents\\Alejo\\Analisis de Datos\\transformers-sentiment-analysis\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas del dataset procesado:\n",
      "                                        review     label\n",
      "0    i loved this product, it works perfectly.  positive\n",
      "1           this exceeded all my expectations!  positive\n",
      "2    amazing quality, totally worth the price.  positive\n",
      "3  i'm extremely satisfied with this purchase.  positive\n",
      "4         great experience, i would buy again.  positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 968/968 [00:00<00:00, 8070.97 examples/s]\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo... esto puede tardar entre 2 y 8 minutos en CPU.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='291' max='291' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [291/291 17:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.254600</td>\n",
       "      <td>0.166183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.072500</td>\n",
       "      <td>0.056005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.051127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo entrenado y guardado correctamente en:\n",
      "models/distilbert-sentiment\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 03 - Train sentiment model (light version)\n",
    "# Model: DistilBERT\n",
    "# ============================================================\n",
    "\n",
    "# 1. Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    DistilBertTokenizerFast,\n",
    "    DistilBertForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "\n",
    "# 2. Load clean dataset\n",
    "df = pd.read_csv(\"../data/processed/clean_reviews_v2.csv\")\n",
    "\n",
    "print(\"First rows of the processed dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# 3. Map labels to numbers (transformers only work with integers)\n",
    "label2id = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "df[\"labels\"] = df[\"label\"].map(label2id)\n",
    "\n",
    "# 4. Convert to HuggingFace Dataset\n",
    "hf_dataset = Dataset.from_pandas(df[[\"review\", \"labels\"]])\n",
    "\n",
    "# 5. Load DistilBERT tokenizer\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# 6. Tokenize texts \n",
    "def tokenize_function(examples):\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"review\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "    # Be sure to include the labels\n",
    "    tokenized[\"labels\"] = examples[\"labels\"]\n",
    "    return tokenized\n",
    "\n",
    "tokenized_dataset = hf_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# DELETE columns that cause errors\n",
    "#tokenized_dataset = tokenized_dataset.remove_columns([\"review\"])\n",
    "\n",
    "\n",
    "# 7. Divide into train/test\n",
    "tokenized_dataset = tokenized_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# 8. Load DistilBERT model\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=3,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "# 9. Configure training (optimized for CPU) - UPDATED VERSION\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../models/distilbert-sentiment\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    use_cpu=True,  # ← UPDATED: no_cuda → use_cpu\n",
    "    logging_steps=10,\n",
    "    remove_unused_columns=False  # ← IMPORTANT: Keep unused columns\n",
    ")\n",
    "\n",
    "# 10. Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"]\n",
    ")\n",
    "\n",
    "# 11. Train\n",
    "print(\"Entrenando modelo... esto puede tardar entre 2 y 8 minutos en CPU.\")\n",
    "trainer.train()\n",
    "\n",
    "# 12. Save final template\n",
    "trainer.save_model(\"../models/distilbert-sentiment\")\n",
    "tokenizer.save_pretrained(\"../models/distilbert-sentiment\")\n",
    "\n",
    "print(\"\\nModel trained and saved correctly in:\")\n",
    "print(\"models/distilbert-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df50324",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
